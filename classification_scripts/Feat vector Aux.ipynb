{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# Create a MirroredStrateg, If Multi-GPU available\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "tf.config.set_soft_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=['/gpu:1','/gpu:2']) \n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "import efficientnet.keras as efn\n",
    "import h5py, glob, re, cv2, math, matplotlib\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools, random\n",
    "\n",
    "# from cnn_utils import *\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from PIL import Image  \n",
    "import pdb\n",
    "from statistics import mode \n",
    "from IPython.display import clear_output\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "np.random.seed(1)\n",
    "# Setting the seed for python random numbers\n",
    "random.seed(1254)\n",
    "# Setting the graph-level random seed.\n",
    "tf.random.set_seed(89)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "!CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=['/gpu:1','/gpu:2'])\n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "# def setup_multi_node_training(): # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE os.environ[“TF_FORCE_GPU_ALLOW_GROWTH”] = “true” tf.config.set_soft_device_placement(True) mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL) # Constructs the configuration run_config = tf.estimator.RunConfig( train_distribute=mirrored_strategy, ) return run_config\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/All_subjects_RDmap.hdf5\n",
      "(527, 605, 128, 128, 3)\n",
      "(527, 605, 19)\n",
      "(132, 605, 128, 128, 3)\n",
      "(132, 605, 19)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/All_subjects_RDmap.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "x_train1 = np.array(data[\"train_img\"])\n",
    "y_train1 = np.array(data[\"train_labels\"])\n",
    "x_test1 = np.array(data[\"test_img\"])\n",
    "y_test1 = np.array(data[\"test_labels\"])\n",
    "data.close()\n",
    "print(x_train1.shape)\n",
    "print(y_train1.shape)\n",
    "print(x_test1.shape)\n",
    "print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/All_subjects_RAmap.hdf5\n",
      "(527, 605, 128, 128, 3)\n",
      "(527, 605, 19)\n",
      "(132, 605, 128, 128, 3)\n",
      "(132, 605, 19)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/All_subjects_RAmap.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "x_train2 = np.array(data[\"train_img\"])\n",
    "y_train2 = np.array(data[\"train_labels\"])\n",
    "x_test2 = np.array(data[\"test_img\"])\n",
    "y_test2 = np.array(data[\"test_labels\"])\n",
    "data.close()\n",
    "print(x_train2.shape)\n",
    "print(y_train2.shape)\n",
    "print(x_test2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 120, 5, 128, 128, 3)\n",
      "(527, 120, 19)\n",
      "(132, 120, 5, 128, 128, 3)\n",
      "(132, 120, 19)\n",
      "(527, 120, 5, 128, 128, 3)\n",
      "(527, 120, 19)\n",
      "(132, 120, 5, 128, 128, 3)\n",
      "(132, 120, 19)\n"
     ]
    }
   ],
   "source": [
    "# windowed RD\n",
    "interval = range(0,600)\n",
    "x_train11 = np.reshape(x_train1[:,interval,:,:,:], (x_train1.shape[0],120,5,x_train1.shape[2],x_train1.shape[3],x_train1.shape[4]))\n",
    "x_test11 = np.reshape(x_test1[:,interval,:,:,:], (x_test1.shape[0],120,5,x_test1.shape[2],x_test1.shape[3],x_test1.shape[4]))\n",
    "y_train11 = np.reshape(np.argmax(y_train1[:,interval,:],-1), (y_train1.shape[0],120,5))\n",
    "y_test11 = np.reshape(np.argmax(y_test1[:,interval,:],-1), (y_test1.shape[0],120,5))\n",
    "y_train11 = to_categorical(np.squeeze(stats.mode(y_train11,2)[0]))\n",
    "y_test11 = to_categorical(np.squeeze(stats.mode(y_test11,2)[0]))\n",
    "print(x_train11.shape)\n",
    "print(y_train11.shape)\n",
    "print(x_test11.shape)\n",
    "print(y_test11.shape)  \n",
    "\n",
    "# windowed RA\n",
    "x_train12 = np.reshape(x_train2[:,interval,:,:,:], (x_train2.shape[0],120,5,x_train2.shape[2],x_train2.shape[3],x_train2.shape[4]))\n",
    "x_test12 = np.reshape(x_test2[:,interval,:,:,:], (x_test2.shape[0],120,5,x_test2.shape[2],x_test2.shape[3],x_test2.shape[4]))\n",
    "y_train12 = np.reshape(np.argmax(y_train2[:,interval,:],-1), (y_train2.shape[0],120,5))\n",
    "y_test12 = np.reshape(np.argmax(y_test2[:,interval,:],-1), (y_test2.shape[0],120,5))\n",
    "y_train12 = to_categorical(np.squeeze(stats.mode(y_train12,2)[0]))\n",
    "y_test12 = to_categorical(np.squeeze(stats.mode(y_test12,2)[0]))\n",
    "print(x_train12.shape)\n",
    "print(y_train12.shape)\n",
    "print(x_test12.shape)\n",
    "print(y_test12.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/All_subjects_spectrogram.hdf5\n",
      "(527, 120, 128, 128, 3)\n",
      "(527, 120, 19)\n",
      "(132, 120, 128, 128, 3)\n",
      "(132, 120, 19)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/All_subjects_spectrogram.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "x_train3 = np.array(data[\"train_img\"])\n",
    "y_train3 = np.array(data[\"train_labels\"])\n",
    "x_test3 = np.array(data[\"test_img\"])\n",
    "y_test3 = np.array(data[\"test_labels\"])\n",
    "data.close()\n",
    "print(x_train3.shape)\n",
    "print(y_train3.shape)\n",
    "print(x_test3.shape)\n",
    "print(y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/All_subjects_margins_and_ctc_label_no_nucleus.hdf5\n",
      "(527, 1482)\n",
      "(527,)\n",
      "(132, 1482)\n",
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/All_subjects_margins_and_ctc_label_no_nucleus.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "margin_tr = np.array(data[\"train_img\"])\n",
    "ctc_tr = np.squeeze(np.array(data[\"train_labels\"])).astype('U12')\n",
    "margin_ts = np.array(data[\"test_img\"])\n",
    "ctc_ts = np.squeeze(np.array(data[\"test_labels\"])).astype('U12')\n",
    "data.close()\n",
    "print(margin_tr.shape)\n",
    "print(ctc_tr.shape)\n",
    "print(margin_ts.shape)\n",
    "print(ctc_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/All_subjects_spect_single.hdf5\n",
      "(527, 128, 128, 3)\n",
      "(132, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/All_subjects_spect_single.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "x_train4 = np.array(data[\"train_img\"])\n",
    "x_test4 = np.array(data[\"test_img\"])\n",
    "data.close()\n",
    "print(x_train4.shape)\n",
    "print(x_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STA LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sta_lta2(vec,nlta,nsta,init_th,stop_th,stepsz):\n",
    "    vec2 = np.zeros(vec.shape)\n",
    "    mask = np.zeros(vec.shape)\n",
    "    state = 0 # '0' nothing, '1' signing\n",
    "    \n",
    "    for i in range(0,len(vec),stepsz):\n",
    "        \n",
    "        if i+nlta+nsta+1 > len(vec):\n",
    "            if state == 1:\n",
    "                stoppt = len(vec)-2\n",
    "                vec2[startpt:stoppt] = vec[startpt:stoppt]\n",
    "                mask[startpt:stoppt] = 1\n",
    "            break\n",
    "            \n",
    "            \n",
    "        longwin = vec[i:i+nlta]\n",
    "        shortwin = vec[i+nlta:i+nlta+nsta]\n",
    "        \n",
    "        if i < nlta and np.mean(longwin) > 150:\n",
    "            vec2[0:i+nsta] = vec[0:i+nsta]\n",
    "            mask[0:i+nsta] = 1\n",
    "        if init_th < sum(shortwin)/sum(longwin):\n",
    "            if state == 0:\n",
    "                startpt = i+nlta\n",
    "                state = 1\n",
    "            if state == 1:\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            if state == 0:\n",
    "                continue\n",
    "            if state == 1:\n",
    "                if sum(shortwin)/sum(longwin) > stop_th:\n",
    "                    continue\n",
    "                else:\n",
    "                    stoppt = i+nlta+int(nsta/2)\n",
    "                    state = 0\n",
    "                    vec2[startpt:stoppt] = vec[startpt:stoppt]\n",
    "                    mask[startpt:stoppt] = 1\n",
    "                    \n",
    "    return vec2, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 24.2\n",
    "nsta_sec = 0.7\n",
    "ratio = margin_tr.shape[-1]/duration\n",
    "nsta = int(nsta_sec*ratio)\n",
    "nlta = int(2*nsta)\n",
    "stepsz = int(0.2*ratio) # 0.2\n",
    "timevec = np.linspace(0,24.2,margin_ts.shape[1])\n",
    "idx = 27\n",
    "init_th = 0.6\n",
    "stop_th = 0.3\n",
    "vecs_train = [] #np.zeros(np.argmax(margin_tr,-1).shape)\n",
    "mask_train = [] #np.zeros(np.argmax(margin_tr,-1).shape)\n",
    "vecs_test = [] #np.zeros(np.argmax(margin_ts,-1).shape)\n",
    "mask_test = [] #np.zeros(np.argmax(margin_ts,-1).shape)\n",
    "for i in range(len(margin_tr)):\n",
    "    vecs_train.append(sta_lta2(margin_tr[i],nlta,nsta,init_th,stop_th,stepsz)[0])\n",
    "    mask_train.append(sta_lta2(margin_tr[i],nlta,nsta,init_th,stop_th,stepsz)[1])\n",
    "# mask_train_win = mask_train[:,::5]\n",
    "for i in range(len(margin_ts)):\n",
    "    vecs_test.append(sta_lta2(margin_ts[i],nlta,nsta,init_th,stop_th,stepsz)[0])\n",
    "    mask_test.append(sta_lta2(margin_ts[i],nlta,nsta,init_th,stop_th,stepsz)[1])\n",
    "# mask_test_win = mask_test[:,::5]\n",
    "mask_train = np.array(mask_train)\n",
    "mask_test = np.array(mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask shapes:\n",
      "(527, 605)\n",
      "(132, 605)\n",
      "(527, 120)\n",
      "(132, 120)\n"
     ]
    }
   ],
   "source": [
    "# downsample the mask to vid\n",
    "mask_vid_tr = np.zeros(np.argmax(y_train1,-1).shape)\n",
    "ratio1 = mask_train.shape[-1]/mask_vid_tr.shape[-1]\n",
    "for i in range(len(mask_train)):\n",
    "    for j in range(mask_train.shape[-1]):\n",
    "        if mask_train[i,j] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            mask_vid_tr[i,int(j/ratio1)] = 1\n",
    "mask_vid_ts = np.zeros(np.argmax(y_test1,-1).shape)\n",
    "for i in range(len(mask_test)):\n",
    "    for j in range(mask_test.shape[-1]):\n",
    "        if mask_test[i,j] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            mask_vid_ts[i,int(j/ratio1)] = 1\n",
    "\n",
    "# downsample the mask to spect\n",
    "mask_spect_tr = np.zeros(np.argmax(y_train3,-1).shape)\n",
    "ratio2 = mask_train.shape[-1]/mask_spect_tr.shape[-1]\n",
    "for i in range(len(mask_train)):\n",
    "    for j in range(mask_train.shape[-1]):\n",
    "        if mask_train[i,j] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            mask_spect_tr[i,int(j/ratio2)] = 1\n",
    "mask_spect_ts = np.zeros(np.argmax(y_test3,-1).shape)\n",
    "for i in range(len(mask_test)):\n",
    "    for j in range(mask_test.shape[-1]):\n",
    "        if mask_test[i,j] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            mask_spect_ts[i,int(j/ratio2)] = 1\n",
    "print('Mask shapes:')\n",
    "print(mask_vid_tr.shape)\n",
    "print(mask_vid_ts.shape)\n",
    "print(mask_spect_tr.shape)\n",
    "print(mask_spect_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_counter(mask):\n",
    "    cnt = 0\n",
    "    flag = 0\n",
    "    for i in range(len(mask)):\n",
    "        if flag == 0 and mask[i] == 0:\n",
    "            continue\n",
    "        if flag == 1 and mask[i] == 1:\n",
    "            continue\n",
    "        if flag == 0 and mask[i] == 1:\n",
    "            flag = 1\n",
    "            cnt += 1\n",
    "        if flag == 1 and mask[i] == 0:\n",
    "            flag = 0\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numgest = [gesture_counter(m) for m in mask_spect_ts]\n",
    "sum(numgest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = y_test3.shape[2]\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masker(x, y, mask):\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    flag = 0\n",
    "    for i in range(len(mask)):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if flag == 0 and mask[i,j] == 0:\n",
    "                continue\n",
    "            if flag == 1 and mask[i,j] == 1:\n",
    "                if j == mask.shape[1]-1 and j+1 - startpt > 2:\n",
    "                    stoppt = j+1\n",
    "                    x2.append(x[i,startpt:stoppt])\n",
    "                    y2.append(np.squeeze(np.argmax(y[i,startpt:stoppt],-1)))\n",
    "                else:\n",
    "                    continue\n",
    "            if flag == 0 and mask[i,j] == 1:\n",
    "                flag = 1\n",
    "                startpt = j\n",
    "            if flag == 1 and mask[i,j] == 0:\n",
    "                flag = 0\n",
    "                stoppt = j+1\n",
    "                if stoppt-startpt > 2:\n",
    "                    x2.append(x[i,startpt:stoppt])\n",
    "                    y2.append(np.squeeze(np.argmax(y[i,startpt:stoppt],-1)))\n",
    "    \n",
    "    x2 = np.asarray(x2)\n",
    "    y2 = np.array([to_categorical(y,num_classes=num_class) for y in np.array(y2)])\n",
    "    return x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/.local/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3042,)\n",
      "(3042,)\n",
      "(740,)\n",
      "(740,)\n",
      "(3042,)\n",
      "(3042,)\n",
      "(740,)\n",
      "(740,)\n",
      "(3042,)\n",
      "(3042,)\n",
      "(740,)\n",
      "(740,)\n"
     ]
    }
   ],
   "source": [
    "x1train, y1train = masker(x_train11, y_train3, mask_spect_tr)\n",
    "x1test, y1test = masker(x_test11, y_test3, mask_spect_ts)\n",
    "x2train, y2train = masker(x_train12, y_train3, mask_spect_tr)\n",
    "x2test, y2test = masker(x_test12, y_test3, mask_spect_ts)\n",
    "x3train, y3train = masker(x_train3, y_train3, mask_spect_tr)\n",
    "x3test, y3test = masker(x_test3, y_test3, mask_spect_ts)\n",
    "print(x1train.shape)\n",
    "print(y1train.shape)\n",
    "print(x1test.shape)\n",
    "print(y1test.shape)\n",
    "print(x2train.shape)\n",
    "print(y2train.shape)\n",
    "print(x2test.shape)\n",
    "print(y2test.shape)\n",
    "print(x3train.shape)\n",
    "print(y3train.shape)\n",
    "print(x3test.shape)\n",
    "print(y3test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3042,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_int_train = np.array([np.argmax(y,-1) for y in y3train])\n",
    "y_int_test = np.array([np.argmax(y,-1) for y in y3test])\n",
    "print(y_int_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_asldaily_tr = [] # 0: daily, 1: asl\n",
    "y_twohanded_tr = [] # 0: daily, 1: 1 hand, 2: 2 hand\n",
    "y_loc_tr = [] # major location: 0: daily, 1: body, 2: neutral, 3: head, 4: hand\n",
    "y_mov_tr = [] # movement: 0: daily, 1: curved, 2: straight, 3: backandforth, 4: circular, 5: other\n",
    "y_str_tr = [] # # of strokes: 0: daily, 1: 3, 2: 4, 3: +5\n",
    "\n",
    "y_asldaily_ts = [] # 0: daily, 1: asl\n",
    "y_twohanded_ts = [] # 0: daily, 1: 1 hand, 2: 2 hand\n",
    "y_loc_ts = [] # major location: 0: daily, 1: body, 2: neutral, 3: head, 4: hand\n",
    "y_mov_ts = [] # movement: 0: daily, 1: curved, 2: straight, 3: backandforth, 4: circular, 5: other\n",
    "y_str_ts = [] # # of strokes: 0: daily, 1: 3, 2: 4, 3: +5\n",
    "\n",
    "## asl daily\n",
    "for i in range(len(y_int_train)):\n",
    "    yx = np.zeros(shape=y_int_train[i].shape)\n",
    "    for j in range(len(y_int_train[i])):\n",
    "        if y_int_train[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        else:\n",
    "            yx[j] = 1\n",
    "    y_asldaily_tr.append(to_categorical(yx,2))\n",
    "for i in range(len(y_int_test)):\n",
    "    yx = np.zeros(shape=y_int_test[i].shape)\n",
    "    for j in range(len(y_int_test[i])):\n",
    "        if y_int_test[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        else:\n",
    "            yx[j] = 1\n",
    "    y_asldaily_ts.append(to_categorical(yx,2))\n",
    "    \n",
    "## two hand\n",
    "for i in range(len(y_int_train)):\n",
    "    yx = np.zeros(shape=y_int_train[i].shape)\n",
    "    for j in range(len(y_int_train[i])):\n",
    "        if y_int_train[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_train[i][j] in (9,16):\n",
    "            yx[j] = 1\n",
    "        else:\n",
    "            yx[j] = 2\n",
    "    y_twohanded_tr.append(to_categorical(yx,3))\n",
    "for i in range(len(y_int_test)):\n",
    "    yx = np.zeros(shape=y_int_test[i].shape)\n",
    "    for j in range(len(y_int_test[i])):\n",
    "        if y_int_test[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_test[i][j] in (9,16):\n",
    "            yx[j] = 1\n",
    "        else:\n",
    "            yx[j] = 2\n",
    "    y_twohanded_ts.append(to_categorical(yx,3))\n",
    "\n",
    "## hand loc\n",
    "for i in range(len(y_int_train)):\n",
    "    yx = np.zeros(shape=y_int_train[i].shape)\n",
    "    for j in range(len(y_int_train[i])):\n",
    "        if y_int_train[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_train[i][j] == 4:\n",
    "            yx[j] = 1\n",
    "        elif y_int_train[i][j] in (5,8,14,16):\n",
    "            yx[j] = 2\n",
    "        elif y_int_train[i][j] in (6,9,17,18):\n",
    "            yx[j] = 3\n",
    "        else:\n",
    "            yx[j] = 4\n",
    "    y_loc_tr.append(to_categorical(yx,5))\n",
    "for i in range(len(y_int_test)):\n",
    "    yx = np.zeros(shape=y_int_test[i].shape)\n",
    "    for j in range(len(y_int_test[i])):\n",
    "        if y_int_test[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_test[i][j] == 4:\n",
    "            yx[j] = 1\n",
    "        elif y_int_test[i][j] in (5,8,14,16):\n",
    "            yx[j] = 2\n",
    "        elif y_int_test[i][j] in (6,9,17,18):\n",
    "            yx[j] = 3\n",
    "        else:\n",
    "            yx[j] = 4\n",
    "    y_loc_ts.append(to_categorical(yx,5))\n",
    "\n",
    "## movement type\n",
    "for i in range(len(y_int_train)):\n",
    "    yx = np.zeros(shape=y_int_train[i].shape)\n",
    "    for j in range(len(y_int_train[i])):\n",
    "        if y_int_train[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_train[i][j] in (4,5,9,12):\n",
    "            yx[j] = 1\n",
    "        elif y_int_train[i][j] in (6,7,8,10,14,15,17,18):\n",
    "            yx[j] = 2\n",
    "        elif y_int_train[i][j] == 13:\n",
    "            yx[j] = 3\n",
    "        elif y_int_train[i][j] == 16:\n",
    "            yx[j] = 4\n",
    "        else:\n",
    "            yx[j] = 5\n",
    "    y_mov_tr.append(to_categorical(yx,6))\n",
    "for i in range(len(y_int_test)):\n",
    "    yx = np.zeros(shape=y_int_test[i].shape)\n",
    "    for j in range(len(y_int_test[i])):\n",
    "        if y_int_test[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_test[i][j] in (4,5,9,12):\n",
    "            yx[j] = 1\n",
    "        elif y_int_test[i][j] in (6,7,8,10,14,15,17,18):\n",
    "            yx[j] = 2\n",
    "        elif y_int_test[i][j] == 13:\n",
    "            yx[j] = 3\n",
    "        elif y_int_test[i][j] == 16:\n",
    "            yx[j] = 4\n",
    "        else:\n",
    "            yx[j] = 5\n",
    "    y_mov_ts.append(to_categorical(yx,6))\n",
    "    \n",
    "## # of strokes\n",
    "for i in range(len(y_int_train)):\n",
    "    yx = np.zeros(shape=y_int_train[i].shape)\n",
    "    for j in range(len(y_int_train[i])):\n",
    "        if y_int_train[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_train[i][j] in (4,5,9,10,13,15,18):\n",
    "            yx[j] = 1\n",
    "        elif y_int_train[i][j] in (6,8,12,16,17):\n",
    "            yx[j] = 2\n",
    "        else:\n",
    "            yx[j] = 3\n",
    "    y_str_tr.append(to_categorical(yx,4))\n",
    "for i in range(len(y_int_test)):\n",
    "    yx = np.zeros(shape=y_int_test[i].shape)\n",
    "    for j in range(len(y_int_test[i])):\n",
    "        if y_int_test[i][j] in (0,1,2,3):\n",
    "            continue\n",
    "        elif y_int_test[i][j] in (4,5,9,10,13,15,18):\n",
    "            yx[j] = 1\n",
    "        elif y_int_test[i][j] in (6,8,12,16,17):\n",
    "            yx[j] = 2\n",
    "        else:\n",
    "            yx[j] = 3\n",
    "    y_str_ts.append(to_categorical(yx,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTC labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_ch(num):\n",
    "    label = ''\n",
    "    for ch in num:\n",
    "        label += chr(ord('@') + np.argmax(ch,-1)+1)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert detected labels\n",
    "ctc_tr3 = [num_to_ch(y) for y in y3train]\n",
    "ctc_ts3 = [num_to_ch(y) for y in y3test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  19\n",
      "Characters present:  ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n"
     ]
    }
   ],
   "source": [
    "characters3 = set(char for label in ctc_tr3 for char in label)\n",
    "print(\"Number of unique characters: \", len(characters3))\n",
    "print(\"Characters present: \", sorted(characters3))\n",
    "# print('Labels: ' + str(np.unique(ctc_tr3)))\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_multi_md(data, labels, batch_size=1):              \n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    data is an array  [[[frame1_filename,frame2_filename,…frame16_filename],label1], [[frame1_filename,frame2_filename,…frame16_filename],label2],……….].\n",
    "    \"\"\"\n",
    "    num_samples = data[0].shape[0]\n",
    "    \n",
    "    while True:   \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "    #             print ('starting index: ', offset) \n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples1 = data[0][offset:offset+batch_size]\n",
    "            batch_samples2 = data[1][offset:offset+batch_size]\n",
    "            batch_samples3 = data[2][offset:offset+batch_size]\n",
    "            \n",
    "            label = labels[0][offset:offset+batch_size]\n",
    "            asldaily = labels[1][offset:offset+batch_size]\n",
    "            twohand = labels[2][offset:offset+batch_size]\n",
    "            major = labels[3][offset:offset+batch_size]\n",
    "            move = labels[4][offset:offset+batch_size]\n",
    "            stroke = labels[5][offset:offset+batch_size]\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train1 = []\n",
    "            X_train2 = []\n",
    "            X_train3 = []\n",
    "            y_train = []\n",
    "            y_train2 = []\n",
    "            y_train3 = []\n",
    "            y_train4 = []\n",
    "            y_train5 = []\n",
    "            y_train6 = []\n",
    "            # For each example\n",
    "            for i in range(0,batch_samples1.shape[0]):\n",
    "                X_train1.append(batch_samples1[i])\n",
    "                X_train2.append(batch_samples2[i])\n",
    "                X_train3.append(batch_samples3[i])\n",
    "                y_train.append(np.array([ord(y)%32 for y in label[i]]))\n",
    "                y_train2.append(asldaily[i])\n",
    "                y_train3.append(twohand[i])\n",
    "                y_train4.append(major[i])\n",
    "                y_train5.append(move[i])\n",
    "                y_train6.append(stroke[i])\n",
    "                \n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train1 = np.array(X_train1)\n",
    "            X_train2 = np.array(X_train2)\n",
    "            X_train3 = np.array(X_train3)\n",
    "            #X_train = np.rollaxis(X_train,1,4)\n",
    "            y_train = np.array(y_train)\n",
    "            y_train2 = np.array(y_train2)\n",
    "            y_train3 = np.array(y_train3)\n",
    "            y_train4 = np.array(y_train4)\n",
    "            y_train5 = np.array(y_train5)\n",
    "            y_train6 = np.array(y_train6)\n",
    "            \n",
    "            feat_vec = np.tile(np.concatenate((y_train2,y_train3,y_train4,y_train5,y_train6),-1),(1,4,1))\n",
    "            \n",
    "            # yield the next training batch            \n",
    "            yield [X_train3, y_train, feat_vec]#, [y_train, y_train2, y_train3, y_train4, y_train5, y_train6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_multi_nolabel_md(data, batch_size=1):              \n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    data is an array  [[[frame1_filename,frame2_filename,…frame16_filename],label1], [[frame1_filename,frame2_filename,…frame16_filename],label2],……….].\n",
    "    \"\"\"\n",
    "    num_samples = data[0].shape[0]\n",
    "    \n",
    "    while True:   \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "    #             print ('starting index: ', offset) \n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples1 = data[0][offset:offset+batch_size]\n",
    "            batch_samples2 = data[1][offset:offset+batch_size]\n",
    "            batch_samples3 = data[2][offset:offset+batch_size]\n",
    "            \n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train1 = []\n",
    "            X_train2 = []\n",
    "            X_train3 = []\n",
    "            # For each example\n",
    "            for i in range(0,batch_samples1.shape[0]):\n",
    "                X_train1.append(batch_samples1[i])\n",
    "                X_train2.append(batch_samples2[i])\n",
    "                X_train3.append(batch_samples3[i])\n",
    "                \n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train1 = np.array(X_train1)\n",
    "            X_train2 = np.array(X_train2)\n",
    "            X_train3 = np.array(X_train3)\n",
    "            \n",
    "            # yield the next training batch            \n",
    "            yield [X_train3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_generator_multi_md([x1train, x2train, x3train], \n",
    "                                     [ctc_tr3, y_asldaily_tr, y_twohanded_tr, y_loc_tr, y_mov_tr, y_str_tr])\n",
    "validation_dataset = data_generator_multi_md([x1test, x2test, x3test], \n",
    "                                     [ctc_ts3, y_asldaily_ts, y_twohanded_ts, y_loc_ts, y_mov_ts, y_str_ts])\n",
    "predict_generator = data_generator_multi_nolabel_md([x1test, x2test, x3test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 320, 20)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x[-1]\n",
    "np.tile(z,(1,4,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 128, 128, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (None,x3train[0].shape[1],x3train[0].shape[2],x3train[0].shape[3])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(Layer):\n",
    "    def __init__(self, name=None, **kwargs):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_md_feat(): # \n",
    "    with tf.device('/gpu:2'):\n",
    "        \n",
    "        inputlayer = Input(shape = input_shape, name=\"image\")\n",
    "        labels = Input(name=\"label\", shape=(None,))#, dtype=\"float32\")\n",
    "        feat_vec = Input(name=\"feats\", shape=(None,20))\n",
    "        \n",
    "        x = TimeDistributed(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))(inputlayer)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)\n",
    "        x = TimeDistributed(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))(x)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)\n",
    "        x = TimeDistributed(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))(x)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(4,1)))(x)\n",
    "#         x = TimeDistributed(Flatten())(x)\n",
    "        \n",
    "        new_shape = (-1, (128//2**3) *64)\n",
    "        cnv1 = Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "        cnv1 = Dense(64, activation=\"relu\", name=\"dense1\")(cnv1)\n",
    "        cnv1 = Dropout(0.5)(cnv1)\n",
    "#         x = Bidirectional(LSTM(128, dropout=0.5, return_sequences=True))(x)\n",
    "        cnv1 = Bidirectional(LSTM(128, dropout=0.5, return_sequences=True))(cnv1)\n",
    "        cnv1 = concatenate([cnv1,feat_vec])\n",
    "        \n",
    "        x2 = Dense(len(characters3) + 2, activation='softmax', name=\"dense2\")(cnv1)\n",
    "        out_ctc = CTCLayer(name=\"ctc_loss\")(labels, x2)\n",
    "        \n",
    "#         cnv2 = TimeDistributed(Flatten(), name=\"flat\")(cnv1)\n",
    "#         out_asldaily = TimeDistributed(Dense(2, activation='softmax'), name=\"asldaily\")(cnv1)\n",
    "#         out_twohanded = TimeDistributed(Dense(3, activation='softmax'), name=\"twohanded\")(cnv1)\n",
    "#         out_major = TimeDistributed(Dense(5, activation='softmax'), name=\"major\")(cnv1)\n",
    "#         out_movement = TimeDistributed(Dense(6, activation='softmax'), name=\"movement\")(cnv1)\n",
    "#         out_stroke = TimeDistributed(Dense(4, activation='softmax'), name=\"stroke\")(cnv1)\n",
    "        \n",
    "#         losses = {\n",
    "#             \"ctc_loss\": None,\n",
    "#             \"aux_loss\": \"categorical_crossentropy\"\n",
    "#         }\n",
    "# #         metrics=['mse','accuracy']\n",
    "#         lossWeights = {\"ctc_loss\": 1.0, \"aux_loss\": 1.0}\n",
    "\n",
    "        model = keras.Model(inputs = [inputlayer, labels, feat_vec], outputs = [out_ctc],#, out_asldaily, out_twohanded,\n",
    "#                                                                      out_major, out_movement, out_stroke], \n",
    "                           name=\"ctc_model\")\n",
    "        opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "        \n",
    "#         model.compile(optimizer=opt,  loss = losses, loss_weights = lossWeights)#, metrics = metrics)\n",
    "        \n",
    "        model.compile(optimizer=opt)#, loss_weights = [1, 0.2, 0.2, 0.2, 0.2,0.2,])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctc_md_feat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "early_stopping_patience = 10\n",
    "# Add early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    7.730, max:   17.793, cur:    7.730)\n",
      "\tvalidation       \t (min:    7.593, max:    9.655, cur:    7.593)\n",
      "3042/3042 [==============================] - 57s 19ms/step - loss: 7.7304 - val_loss: 7.5933\n",
      "Epoch 3/100\n",
      " 434/3042 [===>..........................] - ETA: 43s - loss: 6.2752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-df628f1785f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlotLossesKerasTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    batch_size = 1,\n",
    "    epochs=100,\n",
    "    steps_per_epoch = len(x3train), validation_steps = len(x3test),\n",
    "    callbacks=[early_stopping, PlotLossesKerasTF()],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"feats_3:0\", shape=(None, None, 20), dtype=float32) at layer \"concatenate_5\". The following previous layers were accessed without issue: ['time_distributed_35', 'time_distributed_36', 'time_distributed_37', 'time_distributed_38', 'time_distributed_39', 'time_distributed_40', 'time_distributed_41', 'reshape', 'dense1', 'dropout_5', 'bidirectional_5']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-ec4ab4ffe853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the prediction model by extracting layers till the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m prediction_model = keras.models.Model(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# prediction_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0;31m# Functional model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m#     'arguments during initialization. Got an unexpected argument:')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 191\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    929\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"feats_3:0\", shape=(None, None, 20), dtype=float32) at layer \"concatenate_5\". The following previous layers were accessed without issue: ['time_distributed_35', 'time_distributed_36', 'time_distributed_37', 'time_distributed_38', 'time_distributed_39', 'time_distributed_40', 'time_distributed_41', 'reshape', 'dense1', 'dropout_5', 'bidirectional_5']"
     ]
    }
   ],
   "source": [
    "# Get the prediction model by extracting layers till the output layer\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "# prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b7b468ca4378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-b7b468ca4378>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred = [np.argmax(np.squeeze(prediction_model.predict(next(predict_generator))),-1) for i in range(len(x3test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best path decoding\n",
    "pred_labels = []\n",
    "\n",
    "cnt = 1\n",
    "for p in pred:\n",
    "    label = ''\n",
    "    for num in p:\n",
    "        if chr(ord('@')+num) == 'T':# or chr(ord('@')+num) == 'A':\n",
    "            continue\n",
    "        label = label + chr(ord('@')+num)\n",
    "    pred_labels.append(label)\n",
    "pred_labels = np.array(pred_labels)  \n",
    "print(pred_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "mode_orig = [max(Counter(y)) for y in ctc_ts3]\n",
    "mode_pred = [max(Counter(y)) if len(y) != 0 else 'A' for y in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = [mode_pred[i] == mode_orig[i] for i in range(len(ctc_ts3)) if len(mode_pred[i]) != 0]\n",
    "trues = np.sum(cmp)\n",
    "acc = trues/len(cmp)*100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
