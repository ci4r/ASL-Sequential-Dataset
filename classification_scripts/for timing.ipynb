{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# Create a MirroredStrateg, If Multi-GPU available\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "tf.config.set_soft_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=['/gpu:1','/gpu:2']) \n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import efficientnet.keras as efn\n",
    "import h5py, glob, re, cv2, math, matplotlib, pickle, gc\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools, random\n",
    "from collections import Counter\n",
    "# from cnn_utils import *\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from PIL import Image  \n",
    "import pdb\n",
    "from statistics import mode \n",
    "from IPython.display import clear_output\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "np.random.seed(1)\n",
    "# Setting the seed for python random numbers\n",
    "random.seed(1254)\n",
    "# Setting the graph-level random seed.\n",
    "tf.random.set_seed(89)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "!CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=['/gpu:1','/gpu:2'])\n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "# print('Number of GPUs being used: {}'.format(strategy.num_replicas_in_sync))\n",
    "# def setup_multi_node_training(): # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE os.environ[“TF_FORCE_GPU_ALLOW_GROWTH”] = “true” tf.config.set_soft_device_placement(True) mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL) # Constructs the configuration run_config = tf.estimator.RunConfig( train_distribute=mirrored_strategy, ) return run_config\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 120, 128, 128, 3)\n",
      "(200, 120, 128, 128, 3)\n",
      "(800, 120, 19)\n",
      "(200, 120, 19)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# filename = 'Datasets/final_imit_spec.pkl'\n",
    "# filename = 'Datasets/final_imit_spec2_128.pkl'\n",
    "filename = 'Datasets/final_imit_spec2_128_last.pkl'\n",
    "with open(filename, 'rb') as input:\n",
    "    x = pickle.load(input)\n",
    "imit_train_images, imit_test_images, imit_y_train, imit_y_test, imit_env_train, imit_env_test = [x[0], x[1]\n",
    "                                                                                                , x[2], x[3]\n",
    "                                                                                                , x[4], x[5]]\n",
    "print(imit_train_images.shape)\n",
    "print(imit_test_images.shape)\n",
    "print(imit_y_train.shape)\n",
    "print(imit_y_test.shape)\n",
    "print(imit_env_train.shape)\n",
    "print(imit_env_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Datasets/final_native_spec.pkl'\n",
    "# with open(filename, 'rb') as input:\n",
    "#     x = pickle.load(input)\n",
    "# native_train_images, native_test_images, native_y_train, native_y_test, native_env_train, native_env_test = [x[0], x[1]\n",
    "#                                                                                                 , x[2], x[3]\n",
    "#                                                                                                 , x[4], x[5]]\n",
    "# print(len(native_train_images))\n",
    "# print(len(native_test_images))\n",
    "# print(native_y_train.shape)\n",
    "# print(native_y_test.shape)\n",
    "# print(native_env_train.shape)\n",
    "# print(native_env_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STA LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sta_lta2(vec,nlta,nsta,init_th,stop_th,stepsz):\n",
    "    vec2 = np.zeros(vec.shape)\n",
    "    mask = np.zeros(vec.shape)\n",
    "    state = 0 # '0' nothing, '1' signing\n",
    "    \n",
    "    for i in range(0,len(vec),stepsz):\n",
    "        \n",
    "        if i+nlta+nsta+1 > len(vec):\n",
    "            if state == 1:\n",
    "                stoppt = len(vec)-2\n",
    "                vec2[startpt:stoppt] = vec[startpt:stoppt]\n",
    "                mask[startpt:stoppt] = 1\n",
    "            break\n",
    "            \n",
    "            \n",
    "        longwin = vec[i:i+nlta]\n",
    "        shortwin = vec[i+nlta:i+nlta+nsta]\n",
    "        \n",
    "        if i < nlta and np.mean(longwin) > 150:\n",
    "            vec2[0:i+nsta] = vec[0:i+nsta]\n",
    "            mask[0:i+nsta] = 1\n",
    "        if init_th < sum(shortwin)/sum(longwin):\n",
    "            if state == 0:\n",
    "                startpt = i+nlta\n",
    "                state = 1\n",
    "            if state == 1:\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            if state == 0:\n",
    "                continue\n",
    "            if state == 1:\n",
    "                if sum(shortwin)/sum(longwin) > stop_th:\n",
    "                    continue\n",
    "                else:\n",
    "                    stoppt = i+nlta+int(nsta/2)\n",
    "                    state = 0\n",
    "                    vec2[startpt:stoppt] = vec[startpt:stoppt]\n",
    "                    mask[startpt:stoppt] = 1\n",
    "                    \n",
    "    return vec2, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duration = 24.2\n",
    "nsta_sec = 0.7\n",
    "ratio = imit_env_train[0].shape[-1]/duration\n",
    "nsta = int(nsta_sec*ratio)\n",
    "nlta = int(2*nsta)\n",
    "stepsz = int(0.2*ratio) # 0.2\n",
    "timevec = np.linspace(0,24.2,imit_env_train[0].shape[-1])\n",
    "idx = 27\n",
    "init_th = 0.6\n",
    "stop_th = 0.3\n",
    "vecs_train = [] #np.zeros(np.argmax(margin_tr,-1).shape)\n",
    "mask_train = [] #np.zeros(np.argmax(margin_tr,-1).shape)\n",
    "vecs_test = [] #np.zeros(np.argmax(margin_ts,-1).shape)\n",
    "mask_test = [] #np.zeros(np.argmax(margin_ts,-1).shape)\n",
    "for i in range(len(imit_env_train)):\n",
    "    vecs_train.append(sta_lta2(imit_env_train[i],nlta,nsta,init_th,stop_th,stepsz)[0])\n",
    "    mask_train.append(sta_lta2(imit_env_train[i],nlta,nsta,init_th,stop_th,stepsz)[1])\n",
    "# mask_train_win = mask_train[:,::5]\n",
    "for i in range(len(imit_env_test)):\n",
    "    vecs_test.append(sta_lta2(imit_env_test[i],nlta,nsta,init_th,stop_th,stepsz)[0])\n",
    "    mask_test.append(sta_lta2(imit_env_test[i],nlta,nsta,init_th,stop_th,stepsz)[1])\n",
    "# mask_test_win = mask_test[:,::5]\n",
    "mask_train = np.array(mask_train)\n",
    "mask_test = np.array(mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 3\n",
    "# plt.plot(timevec,imit_env_test[idx]/max(imit_env_test[idx]),color='black')\n",
    "# plt.plot(timevec,mask_test[idx],linewidth=3,color='red')\n",
    "# plt.legend(['Euclidean Distance','STA/LTA Detector'], loc = 'upper right', fontsize = 'xx-large')\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(12,6)\n",
    "# plt.xticks(fontsize=19)\n",
    "# plt.yticks(fontsize=19)\n",
    "# plt.xlabel('Time (sec)',fontsize=19, fontname='Comic Sans MS')\n",
    "# plt.ylabel('Normalized Euclidean Distance',fontsize=19)\n",
    "# # plt.savefig(str(idx)+' gesture detect.png',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_counter(mask):\n",
    "    cnt = 0\n",
    "    flag = 0\n",
    "    for i in range(len(mask)):\n",
    "        if flag == 0 and mask[i] == 0:\n",
    "            continue\n",
    "        if flag == 1 and mask[i] == 1:\n",
    "            continue\n",
    "        if flag == 0 and mask[i] == 1:\n",
    "            flag = 1\n",
    "            cnt += 1\n",
    "        if flag == 1 and mask[i] == 0:\n",
    "            flag = 0\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numgest = [gesture_counter(m) for m in mask_test]\n",
    "sum(numgest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masker(x, y, mask):\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    flag = 0\n",
    "    for i in range(len(mask)):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if flag == 0 and mask[i,j] == 0:\n",
    "                continue\n",
    "            if flag == 1 and mask[i,j] == 1:\n",
    "                if j == mask.shape[1]-1 and j+1 - startpt > 2:\n",
    "                    stoppt = j+1\n",
    "                    x2.append(x[i,startpt:stoppt])\n",
    "                    y2.append(y[i,startpt:stoppt])\n",
    "                else:\n",
    "                    continue\n",
    "            if flag == 0 and mask[i,j] == 1:\n",
    "                flag = 1\n",
    "                startpt = j\n",
    "            if flag == 1 and mask[i,j] == 0:\n",
    "                flag = 0\n",
    "                stoppt = j+1\n",
    "                if stoppt-startpt > 2:\n",
    "                    x2.append(x[i,startpt:stoppt])\n",
    "                    y2.append(y[i,startpt:stoppt])\n",
    "    \n",
    "    x2 = np.asarray(x2)\n",
    "    y2 = np.array([to_categorical(y,num_classes=num_class) for y in np.array(y2)])\n",
    "    return x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_mask(mask, des_len):\n",
    "    return np.array([mask[int(len(mask)/des_len*i)] for i in range(des_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 120)\n",
      "(200, 120)\n",
      "(800, 120, 19)\n",
      "(200, 120, 19)\n",
      "(800, 120, 19, 19)\n",
      "(200, 120, 19, 19)\n"
     ]
    }
   ],
   "source": [
    "des_len = imit_train_images.shape[1]\n",
    "mask_down_train = np.array([down_mask(mask, des_len) for mask in mask_train])\n",
    "mask_down_test = np.array([down_mask(mask, des_len) for mask in mask_test])\n",
    "y_down_train = np.array([down_mask(y, des_len) for y in imit_y_train])\n",
    "y_down_test = np.array([down_mask(y, des_len) for y in imit_y_test])\n",
    "y_down_train_cat = to_categorical(y_down_train, num_classes=num_class)\n",
    "y_down_test_cat = to_categorical(y_down_test, num_classes=num_class)\n",
    "print(mask_down_train.shape)\n",
    "print(mask_down_test.shape)\n",
    "print(y_down_train.shape)\n",
    "print(y_down_test.shape)\n",
    "print(y_down_train_cat.shape)\n",
    "print(y_down_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735,)\n",
      "(4735,)\n",
      "(1190,)\n",
      "(1190,)\n"
     ]
    }
   ],
   "source": [
    "x3train, y3train = masker(imit_train_images, np.argmax(y_down_train,-1), mask_down_train)\n",
    "x3test, y3test = masker(imit_test_images, np.argmax(y_down_test,-1), mask_down_test) \n",
    "print(x3train.shape)\n",
    "print(y3train.shape)\n",
    "print(x3test.shape)\n",
    "print(y3test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1061,\n",
       "         10: 168,\n",
       "         11: 156,\n",
       "         12: 148,\n",
       "         3: 789,\n",
       "         2: 455,\n",
       "         4: 163,\n",
       "         0: 92,\n",
       "         16: 165,\n",
       "         17: 166,\n",
       "         18: 172,\n",
       "         7: 147,\n",
       "         8: 159,\n",
       "         9: 152,\n",
       "         5: 154,\n",
       "         6: 140,\n",
       "         13: 143,\n",
       "         14: 145,\n",
       "         15: 160})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [stats.mode(np.argmax(y,-1))[0] for y in y3train]\n",
    "c = [int(x) for x in classes]\n",
    "Counter(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4643,)\n",
      "(4643,)\n",
      "(1164,)\n",
      "(1164,)\n"
     ]
    }
   ],
   "source": [
    "# eliminate zeros md\n",
    "x6train = np.array([x3train[i] for i in range(len(y3train)) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "y6train = np.array([y3train[i] for i in range(len(y3train)) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "x6test = np.array([x3test[i] for i in range(len(y3test)) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "y6test = np.array([y3test[i] for i in range(len(y3test)) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "print(x6train.shape)\n",
    "print(y6train.shape)\n",
    "print(x6test.shape)\n",
    "print(y6test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD - RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filename = 'Datasets/final_imit_RD-RA2.pkl'\n",
    "# with open(filename, 'rb') as input:\n",
    "#     x = pickle.load(input)\n",
    "# imit_y_train_RD, imit_y_test_RD, imit_RD_train, imit_RA_train, imit_RD_test, imit_RA_test = [x[0], x[1]\n",
    "#                                                                                                 , x[2], x[3]\n",
    "#                                                                                                 , x[4], x[5]]\n",
    "# print(imit_y_train_RD.shape)\n",
    "# print(imit_y_test_RD.shape)\n",
    "# print(imit_RD_train.shape)\n",
    "# print(imit_RA_train.shape)\n",
    "# print(imit_RD_test.shape)\n",
    "# print(imit_RA_test.shape)\n",
    "# del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: Datasets/final_imit_RD-RA2_128_last.hdf5\n",
      "(800, 605, 128, 128, 3)\n",
      "(800, 605, 128, 128, 3)\n",
      "(200, 605, 128, 128, 3)\n",
      "(200, 605, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Datasets/final_imit_RD-RA2_128_last.hdf5'\n",
    "data = h5py.File(filename, \"r\")\n",
    "print('Selected File: '+str(filename))\n",
    "imit_RD_train = np.array(data[\"train_RD\"])\n",
    "imit_RA_train = np.array(data[\"train_RA\"])\n",
    "imit_RD_test = np.array(data[\"test_RD\"])\n",
    "imit_RA_test = np.array(data[\"test_RA\"])\n",
    "data.close()\n",
    "print(imit_RD_train.shape)\n",
    "print(imit_RA_train.shape)\n",
    "print(imit_RD_test.shape)\n",
    "print(imit_RA_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 120, 5, 128, 128, 3)\n",
      "(200, 120, 5, 128, 128, 3)\n",
      "(800, 120, 5, 128, 128, 3)\n",
      "(200, 120, 5, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# windowed RD\n",
    "interval = range(0,600)\n",
    "x_train11 = np.reshape(imit_RD_train[:,interval,:,:,:], (imit_RD_train.shape[0],120,5,imit_RD_train.shape[2],imit_RD_train.shape[3],imit_RD_train.shape[4]))\n",
    "x_test11 = np.reshape(imit_RD_test[:,interval,:,:,:], (imit_RD_test.shape[0],120,5,imit_RD_test.shape[2],imit_RD_test.shape[3],imit_RD_test.shape[4]))\n",
    "# y_train11 = np.reshape(imit_y_train_RD[:,interval], (imit_y_train_RD.shape[0],120,5))\n",
    "# y_test11 = np.reshape(imit_y_test_RD[:,interval], (imit_y_test_RD.shape[0],120,5))\n",
    "# y_train11 = to_categorical(np.squeeze(stats.mode(y_train11,2)[0]))\n",
    "# y_test11 = to_categorical(np.squeeze(stats.mode(y_test11,2)[0]))\n",
    "print(x_train11.shape)\n",
    "# print(y_train11.shape)\n",
    "print(x_test11.shape)\n",
    "# print(y_test11.shape)  \n",
    "\n",
    "# windowed RA\n",
    "x_train12 = np.reshape(imit_RA_train[:,interval,:,:,:], (imit_RA_train.shape[0],120,5,imit_RA_train.shape[2],imit_RA_train.shape[3],imit_RA_train.shape[4]))\n",
    "x_test12 = np.reshape(imit_RA_test[:,interval,:,:,:], (imit_RA_test.shape[0],120,5,imit_RA_test.shape[2],imit_RA_test.shape[3],imit_RA_test.shape[4]))\n",
    "print(x_train12.shape)\n",
    "print(x_test12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735,)\n",
      "(4735,)\n",
      "(1190,)\n",
      "(1190,)\n",
      "(4735,)\n",
      "(1190,)\n"
     ]
    }
   ],
   "source": [
    "# x1train, y1train = masker(x_train11, np.argmax(y_train11,-1), mask_down_train)\n",
    "# x1test, y1test = masker(x_test11, np.argmax(y_test11,-1), mask_down_test)\n",
    "# x2train, y1train = masker(x_train12, np.argmax(y_train11,-1), mask_down_train)\n",
    "# x2test, y1test = masker(x_test12, np.argmax(y_test11,-1), mask_down_test)\n",
    "x1train, y1train = masker(x_train11, y_down_train, mask_down_train)\n",
    "x1test, y1test = masker(x_test11, y_down_test, mask_down_test)\n",
    "x2train, y1train = masker(x_train12, y_down_train, mask_down_train)\n",
    "x2test, y1test = masker(x_test12, y_down_test, mask_down_test)\n",
    "print(x1train.shape)\n",
    "print(y1train.shape)\n",
    "print(x1test.shape)\n",
    "print(y1test.shape)\n",
    "print(x2train.shape)\n",
    "print(x2test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4643,)\n",
      "(1164,)\n",
      "(4643,)\n",
      "(1164,)\n"
     ]
    }
   ],
   "source": [
    "x10train = np.array([x1train[i] for i in range(len(y3train)) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "x11train = np.array([x2train[i] for i in range(len(y3train)) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "# y10train = np.array([y1train[i] for i in range(len(y3train)) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "x10test = np.array([x1test[i] for i in range(len(y3test)) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "x11test = np.array([x2test[i] for i in range(len(y3test)) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "# y10test = np.array([y1test[i] for i in range(len(y3test)) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "print(x10train.shape)\n",
    "# print(y10train.shape)\n",
    "print(x10test.shape)\n",
    "# print(y10test.shape)\n",
    "print(x11train.shape)\n",
    "print(x11test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 128, 128, 3)\n",
      "(95, 128, 128, 3)\n",
      "(4643,)\n",
      "(1164,)\n"
     ]
    }
   ],
   "source": [
    "x12train = np.array([x.reshape(x.shape[0]*x.shape[1],x.shape[2],x.shape[3],x.shape[4]) for x in x10train])\n",
    "x13train = np.array([x.reshape(x.shape[0]*x.shape[1],x.shape[2],x.shape[3],x.shape[4]) for x in x11train])\n",
    "x12test = np.array([x.reshape(x.shape[0]*x.shape[1],x.shape[2],x.shape[3],x.shape[4]) for x in x10test])\n",
    "x13test = np.array([x.reshape(x.shape[0]*x.shape[1],x.shape[2],x.shape[3],x.shape[4]) for x in x11test])\n",
    "print(x12train[0].shape)\n",
    "print(x12test[0].shape)\n",
    "print(x13train.shape)\n",
    "print(x13test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of f-b-f RD:  (None, 5, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape_vid = (None, x_train11[0].shape[1],x_train11[0].shape[2],x_train11[0].shape[3],x_train11[0].shape[4])\n",
    "print('Input shape of f-b-f RD: ',input_shape_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of f-b-f mD:  (None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape11 = (None,x3train[0].shape[1],x3train[0].shape[2],x3train[0].shape[3])\n",
    "print('Input shape of f-b-f mD: ',input_shape11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_patience = 10\n",
    "# Add early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=early_stopping_patience, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor=0.5, patience=0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4735/4735 [00:01<00:00, 3013.91it/s]\n",
      "100%|██████████| 1190/1190 [00:00<00:00, 3153.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4643, 19)\n",
      "(1164, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ytrain = np.array([np.squeeze(to_categorical(stats.mode(np.argmax(y3train[i],-1))[0],19)) for i in tqdm(range(len(y3train)), position = 0, leave = True) if stats.mode(np.argmax(y3train[i],-1))[0] != 0])\n",
    "ytest = np.array([np.squeeze(to_categorical(stats.mode(np.argmax(y3test[i],-1))[0],19)) for i in tqdm(range(len(y3test)), position = 0, leave = True) if stats.mode(np.argmax(y3test[i],-1))[0] != 0])\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_finder(y): # finds the mode that is not zero\n",
    "    y = np.argmax(y,-1)\n",
    "    mode = stats.mode(y)[0]\n",
    "    if mode == 0:\n",
    "        mask = y == mode\n",
    "        y = y[~np.ma.masked_array(y, mask = mask).mask]\n",
    "        new_mode = stats.mode(y)[0]\n",
    "    else:\n",
    "        new_mode = mode\n",
    "    return np.squeeze(new_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmodel(fname):\n",
    "    model_file = 'Models/' + fname + '.json'\n",
    "    w_file = 'Models/' + fname + '.h5'\n",
    "    json_file = open(model_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model_md = model_from_json(loaded_model_json)\n",
    "    model_md.load_weights(w_file)\n",
    "    return model_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = [1, 2, 3, 6, 12, 24]\n",
    "mod_md_1sec = loadmodel('final varying md len_'+str(seqlen[-1]))\n",
    "mod_md_2sec = loadmodel('final varying md len_'+str(seqlen[-2]))\n",
    "mod_rd_1sec = loadmodel('final varying rd len_'+str(seqlen[-1]))\n",
    "mod_rd_2sec = loadmodel('final varying rd len_'+str(seqlen[-2]))\n",
    "mod_ra_1sec = loadmodel('final varying ra len_'+str(seqlen[-1]))\n",
    "mod_ra_2sec = loadmodel('final varying ra len_'+str(seqlen[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_pred(data, labels, batch_size=1):              \n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    data is an array  [[[frame1_filename,frame2_filename,…frame16_filename],label1], [[frame1_filename,frame2_filename,…frame16_filename],label2],……….].\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "    \n",
    "    while True:   \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "    #             print ('starting index: ', offset) \n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = data[offset:offset+batch_size]\n",
    "            label = labels[offset:offset+batch_size]\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            # For each example\n",
    "            for i in range(0,batch_samples.shape[0]):\n",
    "                X_train.append(batch_samples[i])\n",
    "                y_train.append(label[i])\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            #X_train = np.rollaxis(X_train,1,4)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            # yield the next training batch            \n",
    "            yield X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:49<00:00, 201.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "201.83033652305602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = imit_test_images.reshape(-1,120//seqlen[-1],128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-1],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_md1 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_md_1sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_md1.append(time.time() - t)\n",
    "np.mean(elapsed_md1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:18<00:00, 111.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111.72134108543396"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = imit_test_images.reshape(-1,120//seqlen[-2],128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-2],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_md2 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_md_2sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_md2.append(time.time() - t)\n",
    "np.mean(elapsed_md2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:17<00:00, 207.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "207.4619478702545"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = x_test11.reshape(-1,120//seqlen[-1],5,128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-1],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_rd1 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_rd_1sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_rd1.append(time.time() - t)\n",
    "np.mean(elapsed_rd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:28<00:00, 125.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125.70125155448913"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = x_test11.reshape(-1,120//seqlen[-2],5,128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-2],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_rd2 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_rd_2sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_rd2.append(time.time() - t)\n",
    "np.mean(elapsed_rd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:08<00:00, 205.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "205.7601861476898"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = x_test12.reshape(-1,120//seqlen[-1],5,128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-1],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_ra1 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_rd_1sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_ra1.append(time.time() - t)\n",
    "np.mean(elapsed_ra1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:15<00:00, 123.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123.07286176681518"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xts_md = x_test12.reshape(-1,120//seqlen[-2],5,128,128,3)\n",
    "yts = imit_y_test.reshape(-1,120//seqlen[-2],19)\n",
    "validation_dataset = data_generator_pred(xts_md, yts)\n",
    "elapsed_ra2 = []\n",
    "for i in tqdm(range(5),position=0):\n",
    "    t = time.time()\n",
    "    p = [np.squeeze(mod_rd_2sec.predict(next(validation_dataset))) for i in range(len(yts))]\n",
    "    elapsed_ra2.append(time.time() - t)\n",
    "np.mean(elapsed_ra2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
