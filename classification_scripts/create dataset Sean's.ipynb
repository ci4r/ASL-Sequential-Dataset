{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/*/microDoppler/cut/*.png\n",
      "3954\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "\n",
    "shuffle_data = True  # shuffle the addresses\n",
    "\n",
    "hdf5_path = 'Datasets/blake_md_trigger_128x128.hdf5'  # file path for the created .hdf5 file\n",
    "\n",
    "train_path = '/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/*/microDoppler/cut/*.png' # the original data path\n",
    "print(train_path)\n",
    "\n",
    "# get all the image paths \n",
    "addrs = glob.glob(train_path)\n",
    "print(len(addrs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(addrs)):\n",
    "    idx = max([pos for pos, char in enumerate(addrs[i]) if char == '_'])\n",
    "    dot = max([pos for pos, char in enumerate(addrs[i]) if char == '.'])\n",
    "    clas = addrs[i][idx+1:dot]\n",
    "    labels.append(int(clas))\n",
    "#     print(str(i)+'. idx: '+str(idx)+', dot: '+str(dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/*/blake free seq/microDoppler/cut/*.png\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "test_path = '/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/*/blake free seq/microDoppler/cut/*.png' # the original data path\n",
    "print(test_path)\n",
    "\n",
    "# get all the image paths \n",
    "addrs_ts = glob.glob(test_path)\n",
    "print(len(addrs_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ts = []\n",
    "addrs_ts2 = []\n",
    "for i in range(len(addrs_ts)):\n",
    "    idx = max([pos for pos, char in enumerate(addrs_ts[i]) if char == '_'])\n",
    "    dot = max([pos for pos, char in enumerate(addrs_ts[i]) if char == '.'])\n",
    "    clas = addrs_ts[i][idx+1:dot]\n",
    "    if clas != '0':\n",
    "        labels_ts.append(int(clas))\n",
    "        addrs_ts2.append(addrs_ts[i])\n",
    "#     print(str(i)+'. idx: '+str(idx)+', dot: '+str(dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3954\n",
      "143\n",
      "3954\n",
      "143\n",
      "Train data: 50/3954\n",
      "Train data: 100/3954\n",
      "Train data: 150/3954\n",
      "Train data: 200/3954\n",
      "Train data: 250/3954\n",
      "Train data: 300/3954\n",
      "Train data: 350/3954\n",
      "Train data: 400/3954\n",
      "Train data: 450/3954\n",
      "Train data: 500/3954\n",
      "Train data: 550/3954\n",
      "Train data: 600/3954\n",
      "Train data: 650/3954\n",
      "Train data: 700/3954\n",
      "Train data: 750/3954\n",
      "Train data: 800/3954\n",
      "Train data: 850/3954\n",
      "Train data: 900/3954\n",
      "Train data: 950/3954\n",
      "Train data: 1000/3954\n",
      "Train data: 1050/3954\n",
      "Train data: 1100/3954\n",
      "Train data: 1150/3954\n",
      "Train data: 1200/3954\n",
      "Train data: 1250/3954\n",
      "Train data: 1300/3954\n",
      "Train data: 1350/3954\n",
      "Train data: 1400/3954\n",
      "Train data: 1450/3954\n",
      "Train data: 1500/3954\n",
      "Train data: 1550/3954\n",
      "Train data: 1600/3954\n",
      "Train data: 1650/3954\n",
      "Train data: 1700/3954\n",
      "Train data: 1750/3954\n",
      "Train data: 1800/3954\n",
      "Train data: 1850/3954\n",
      "Train data: 1900/3954\n",
      "Train data: 1950/3954\n",
      "Train data: 2000/3954\n",
      "Train data: 2050/3954\n",
      "Train data: 2100/3954\n",
      "Train data: 2150/3954\n",
      "Train data: 2200/3954\n",
      "Train data: 2250/3954\n",
      "Train data: 2300/3954\n",
      "Train data: 2350/3954\n",
      "Train data: 2400/3954\n",
      "Train data: 2450/3954\n",
      "Train data: 2500/3954\n",
      "Train data: 2550/3954\n",
      "Train data: 2600/3954\n",
      "Train data: 2650/3954\n",
      "Train data: 2700/3954\n",
      "Train data: 2750/3954\n",
      "Train data: 2800/3954\n",
      "Train data: 2850/3954\n",
      "Train data: 2900/3954\n",
      "Train data: 2950/3954\n",
      "Train data: 3000/3954\n",
      "Train data: 3050/3954\n",
      "Train data: 3100/3954\n",
      "Train data: 3150/3954\n",
      "Train data: 3200/3954\n",
      "Train data: 3250/3954\n",
      "Train data: 3300/3954\n",
      "Train data: 3350/3954\n",
      "Train data: 3400/3954\n",
      "Train data: 3450/3954\n",
      "Train data: 3500/3954\n",
      "Train data: 3550/3954\n",
      "Train data: 3600/3954\n",
      "Train data: 3650/3954\n",
      "Train data: 3700/3954\n",
      "Train data: 3750/3954\n",
      "Train data: 3800/3954\n",
      "Train data: 3850/3954\n",
      "Train data: 3900/3954\n",
      "Train data: 3950/3954\n",
      "Test data: 50/143\n",
      "Test data: 100/143\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# label the data as 0=cat, 1=dog\n",
    "\n",
    "labels = [0 if 'towards' in else 1 for addr in addrs] # extra is included in non-vehicles name \n",
    "          \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels)) # use zip() to bind the images and labels together\n",
    "    shuffle(c)\n",
    " \n",
    "    (addrs, labels) = zip(*c)  # *c is used to separate all the tuples in the list c,  \n",
    "                               # \"addrs\" then contains all the shuffled paths and \n",
    "                               # \"labels\" contains all the shuffled labels.\n",
    "                               \n",
    "# Divide the data into 80% for train and 20% for test\n",
    "# train_addrs = addrs[0:int(0.7*len(addrs))]\n",
    "# train_labels = labels[0:int(0.7*len(labels))]\n",
    "train_addrs = addrs\n",
    "train_labels = labels\n",
    "\n",
    "# valid_addrs = addrs[int(0.7*len(addrs)):int(0.8*len(addrs))]\n",
    "# valid_labels = labels[int(0.7*len(labels)):int(0.8*len(addrs))]\n",
    "\n",
    "test_addrs = addrs_ts2\n",
    "test_labels = labels_ts\n",
    "\n",
    "print(len(train_addrs))\n",
    "# print(len(valid_addrs))\n",
    "print(len(test_addrs))\n",
    "print(len(train_labels))\n",
    "# print(len(valid_labels))\n",
    "print(len(test_labels))\n",
    "\n",
    "##################### second part: create the h5py object #####################\n",
    "import numpy as np\n",
    "import h5py, cv2\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "train_shape = (len(train_addrs), im_height, im_width, 3)\n",
    "# valid_shape = (len(valid_addrs), im_width, im_height, 3)\n",
    "test_shape = (len(test_addrs), im_height, im_width, 3)\n",
    "\n",
    "# open a hdf5 file and create earrays \n",
    "f = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "# PIL.Image: the pixels range is 0-255,dtype is uint.\n",
    "# matplotlib: the pixels range is 0-1,dtype is float.\n",
    "f.create_dataset(\"train_img\", train_shape, np.uint8)\n",
    "# f.create_dataset(\"valid_img\", valid_shape, np.uint8)  \n",
    "f.create_dataset(\"test_img\", test_shape, np.uint8)  \n",
    "\n",
    "# the \".create_dataset\" object is like a dictionary, the \"train_labels\" is the key. \n",
    "f.create_dataset(\"train_labels\", (len(train_addrs),), np.uint8)\n",
    "f[\"train_labels\"][...] = train_labels\n",
    "\n",
    "# f.create_dataset(\"valid_labels\", (len(valid_addrs),), np.uint8)\n",
    "# f[\"valid_labels\"][...] = valid_labels\n",
    "\n",
    "f.create_dataset(\"test_labels\", (len(test_addrs),), np.uint8)\n",
    "f[\"test_labels\"][...] = test_labels\n",
    "\n",
    "######################## third part: write the images #########################\n",
    "import cv2\n",
    "\n",
    "# loop over train paths\n",
    "for i in range(len(train_addrs)):\n",
    "  \n",
    "    if i % 50 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)) )\n",
    "\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (im_width, im_height), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    f[\"train_img\"][i, ...] = img[None] \n",
    "\n",
    "    # loop over valid paths\n",
    "# for i in range(len(valid_addrs)):\n",
    "\n",
    "#     if i % 50 == 0 and i > 1:\n",
    "#         print ('Valid data: {}/{}'.format(i, len(valid_addrs)) )\n",
    "        \n",
    "#     addr = valid_addrs[i]\n",
    "#     img = cv2.imread(addr)\n",
    "#     img = cv2.resize(img, (im_width, im_height), interpolation=cv2.INTER_CUBIC)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     f[\"valid_img\"][i, ...] = img[None]\n",
    "    \n",
    "# loop over test paths\n",
    "for i in range(len(test_addrs)):\n",
    "\n",
    "    if i % 50 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)) )\n",
    "        \n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (im_width, im_height), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    f[\"test_img\"][i, ...] = img[None]\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read .h5 file and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3954\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "dataset = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "test_labels = np.array(dataset[\"test_labels\"])\n",
    "# valid_labels = np.array(dataset[\"valid_labels\"])\n",
    "train_labels = np.array(dataset[\"train_labels\"])\n",
    "train_img = np.array(dataset[\"train_img\"])\n",
    "# valid_img = np.array(dataset[\"valid_img\"])\n",
    "test_img = np.array(dataset[\"test_img\"])\n",
    "dataset.close()\n",
    "print(len(train_labels))\n",
    "# print(len(valid_labels))\n",
    "print(len(test_labels))\n",
    "# cv2.imshow('Sample', test_img[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
