{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: Datasets/Blake2_margins_and_ctc_label_no_nucleus.hdf5\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob,h5py, cv2\n",
    "import numpy as np\n",
    "from numpy import dstack\n",
    "from IPython.display import clear_output\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from scipy.signal import resample\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n",
    "duration = 24.2\n",
    "fps = 25\n",
    "sub = 'Blake2'\n",
    "num_frames = duration*fps # axis = 1 dimension, also the # of frames are going to be padded to this value.\n",
    "filename = 'Datasets/'+sub+'_margins_and_ctc_label_no_nucleus.hdf5'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of label files: 23\n",
      "1. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/11010003_1617741768_1.txt\n",
      "2. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/11010003_1617741768_2.txt\n",
      "3. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/11010003_1617741768_3.txt\n",
      "4. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/11010003_1617741768_4.txt\n",
      "5. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/11010003_1617741768_5.txt\n"
     ]
    }
   ],
   "source": [
    "# load labels\n",
    "trainy = '/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/labels/microDoppler/*.txt'\n",
    "trainy_files = sorted(glob.glob(trainy))\n",
    "print('Num. of label files: '+str(len(trainy_files)))\n",
    "for i in range(0,5):\n",
    "    print(str(i+1)+'. ' +trainy_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of label files: 23\n",
      "1. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/envelopes/11010003_1617741768_1.txt\n",
      "2. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/envelopes/11010003_1617741768_2.txt\n",
      "3. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/envelopes/11010003_1617741768_3.txt\n",
      "4. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/envelopes/11010003_1617741768_4.txt\n",
      "5. /mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/6 apr blake/envelopes/11010003_1617741768_5.txt\n"
     ]
    }
   ],
   "source": [
    "# load margins\n",
    "trainpath = '/mnt/HDD01/rspl-admin/DATASETS/Fall Sequential/Outputs/*/envelopes/*.txt'\n",
    "train_files2 = sorted(glob.glob(trainpath))\n",
    "len(train_files2)\n",
    "train_files2[0]\n",
    "train_files = []\n",
    "for i in range(0,len(trainy_files)):\n",
    "#     fname = trainy_files[i][-23:].replace(\"txt\",\"\") + \"txt\"\n",
    "#     fname = trainy_files[i][-30:].replace(\"txt\",\"txt\") # -23 for nonbinary labels\n",
    "#     fname = fname.replace('_binary','')\n",
    "#     fname = trainy_files[i]\n",
    "    slash_idx = trainy_files[i].rfind('/')\n",
    "    fname = trainy_files[i][slash_idx:]\n",
    "    idx = [j for j, s in enumerate(train_files2) if fname in s] #train_files2.index(fname) \n",
    "    if len(idx) == 1:\n",
    "        train_files.append(train_files2[idx[0]])\n",
    "    else:\n",
    "        print('2 identical filenames at i=',str(i))\n",
    "print('Num. of label files: '+str(len(train_files)))\n",
    "for i in range(0,5):    \n",
    "    print(str(i+1)+'. '+train_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading margins #23\n",
      "(23,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "margins = []\n",
    "\n",
    "cnt = 1\n",
    "for file in train_files:\n",
    "    clear_output(wait=True)\n",
    "    print('Loading margins #'+str(cnt))\n",
    "    yx = load_file(file)\n",
    "    margins.append(np.squeeze(np.array(yx)))\n",
    "    cnt += 1\n",
    "# margins = np.squeeze(np.array(margins))\n",
    "margins = np.array(margins)\n",
    "\n",
    "print(margins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1489,)\n",
      "(1488,)\n",
      "(1488,)\n",
      "(1488,)\n",
      "(1488,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(18):\n",
    "    print(margins[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with nucleus and retraction\n",
    "seq1 = np.array([1,2,19,4,20,19,5,20,19,6,20,3])\n",
    "seq2 = np.array([1,2,19,7,20,19,8,20,19,9,20,3])\n",
    "seq3 = np.array([1,2,19,10,20,19,11,20,19,12,20,3])\n",
    "seq4 = np.array([1,2,19,13,20,19,14,20,19,15,20,3])\n",
    "seq5 = np.array([1,2,19,16,20,19,17,20,19,18,20,3])\n",
    "sequences = [seq1,seq2,seq3,seq4,seq5]\n",
    "chr(ord('@')+19)\n",
    "int(trainy_files[0][-22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without nucleus and retraction\n",
    "seq1 = np.array([1,2,4,5,6,3])\n",
    "seq2 = np.array([1,2,7,8,9,3])\n",
    "seq3 = np.array([1,2,10,11,12,3])\n",
    "seq4 = np.array([1,2,13,14,15,3])\n",
    "seq5 = np.array([1,2,16,17,18,3])\n",
    "sequences = [seq1,seq2,seq3,seq4,seq5]\n",
    "chr(ord('@')+19)\n",
    "# int(trainy_files[51][-22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 5, 6, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# label = ''\n",
    "# for ch in sequences[0]:\n",
    "#     label = label + chr(ord('@')+ch)\n",
    "# labels.append(label)\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels #23\n",
      "(23,)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "cnt = 1\n",
    "for file in trainy_files:\n",
    "    clear_output(wait=True)\n",
    "    print('Loading labels #'+str(cnt))\n",
    "    seqnum = int(file[-22])-1\n",
    "    label = ''\n",
    "    for ch in sequences[seqnum]:\n",
    "        label = label + chr(ord('@')+ch)\n",
    "    labels.append(label)\n",
    "    cnt += 1\n",
    "labels = np.array(labels)  \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels #18\n",
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "# Blake's\n",
    "from itertools import groupby \n",
    "labels = []\n",
    "\n",
    "cnt = 1\n",
    "for file in trainy_files:\n",
    "    clear_output(wait=True)\n",
    "    print('Loading labels #'+str(cnt))\n",
    "    yx = load_file(file)\n",
    "    y = [i[0] for i in groupby(yx)]\n",
    "    label = ''\n",
    "    for ch in y[0]:\n",
    "        if ch != 0:\n",
    "            label = label + chr(ord('@')+ch)\n",
    "    label = [i[0] for i in groupby(label)]\n",
    "    label = ''.join(label)\n",
    "    labels.append(label)\n",
    "    cnt += 1\n",
    "labels = np.array(labels)  \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABPQRC'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train\n",
    "# loaded_tr = list()\n",
    "# winsize = 0.2 # sec\n",
    "# totalwin = int(30/winsize)\n",
    "# for name in train_files:\n",
    "#     data = load_file(name)\n",
    "#     loaded_tr.append(data)\n",
    "# # loaded_tr = dstack(loaded_tr) \n",
    "# envelopes = np.swapaxes(np.array(loaded_tr), 1, 2)\n",
    "\n",
    "# loaded_tr = list()\n",
    "# for name in trainy_files:\n",
    "#     data = load_file(name)\n",
    "#     loaded_tr.append(data)\n",
    "# labels = np.array(loaded_tr)    \n",
    "# labels = to_categorical(np.swapaxes(labels, 1, 2))\n",
    "\n",
    "# print(envelopes.shape)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n",
      "(18,)\n",
      "(5,)\n",
      "(5,)\n",
      "# of frames in a class:\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(margins, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "# if Reshape == 1:\n",
    "#     x_train = x_train.reshape(-1,fps,x_train.shape[2],x_train.shape[3],x_train.shape[4])\n",
    "#     x_test = x_test.reshape(-1,fps,x_test.shape[2],x_test.shape[3],x_test.shape[4])\n",
    "#     y_train = y_train.reshape(-1,fps,y_train.shape[2])\n",
    "#     y_test = y_test.reshape(-1,fps,y_test.shape[2])\n",
    "    \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print('# of frames in a class:')\n",
    "# Counter(np.concatenate(np.argmax(y_train, axis=2),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTF encoding to store strings into hdf5\n",
    "utftrain = [y.encode('utf8') for y in y_train]\n",
    "utftest = [y.encode('utf8') for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/Blake2_margins_and_ctc_label_no_nucleus.hdf5 created.\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(filename, mode='w')\n",
    "# f.create_dataset(\"train_img\", x_train.shape, np.uint8)\n",
    "# f.create_dataset(\"test_img\", x_test.shape, np.uint8) \n",
    "dt = h5py.special_dtype(vlen=str)\n",
    "f.create_dataset(\"train_labels\", (len(utftrain),1), dtype = 'S12',data=utftrain)\n",
    "f.create_dataset(\"test_labels\", (len(utftest),1), dtype = 'S12',data=utftest)\n",
    "\n",
    "# blake's\n",
    "dt = h5py.special_dtype(vlen=np.dtype('float64'))\n",
    "f.create_dataset('train_img', (x_train.shape[0],), dtype=dt)\n",
    "f['train_img'][...] = x_train\n",
    "f.create_dataset('test_img', (x_test.shape[0],), dtype=dt)\n",
    "f['test_img'][...] = x_test\n",
    "\n",
    "# f[\"train_img\"][...] = x_train\n",
    "# f[\"test_img\"][...] = x_test\n",
    "# f[\"train_labels\"][...] = utftrain\n",
    "# f[\"test_labels\"][...] = y_test\n",
    "f.close()\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "state": {
    "198b1c2482a344d69143819abc57d8ab": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "925b2dc0719b43b49612d1453eb0a2c3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
